"""
StarClassify-Vis â€”â€” åŸºäº SDSS å¤§æ•°æ®çš„æ’æ˜Ÿå¤šç»´ç‰¹å¾åˆ†ç±»ä¸äº¤äº’å¼ç§‘æ™®å¹³å°

è¯´æ˜ï¼š
- æœ¬æ–‡ä»¶æ˜¯ Streamlit åº”ç”¨å…¥å£ï¼Œæä¾›ä¾§è¾¹æ å¯¼èˆªä¸å¤šä¸ªä¸»è¦é¡µé¢ï¼š
  æ•°æ®æ¦‚è§ˆã€æ¨¡å‹è®­ç»ƒæŠ¥å‘Šã€ç§‘ç ”ç­›é€‰å·¥å…·ã€èµ«ç½—å›¾ç§‘æ™®äº’åŠ¨ã€æ‰¹é‡æ“ä½œã€ä¸»é¢˜è®¾ç½®ã€
  è¯­è¨€è®¾ç½®ã€æ¨¡å‹ç®¡ç†ã€æ•°æ®å¢å¼ºã€é«˜çº§ç­›é€‰ã€è‡ªåŠ¨è°ƒä¼˜ã€ç‰¹å¾åˆ†æã€è®­ç»ƒç›‘æ§ã€æŠ¥å‘Šç”Ÿæˆã€‚
- æ‰€æœ‰ä¸šåŠ¡é€»è¾‘å°è£…åœ¨ starvis åŒ…å†…çš„æ¨¡å—å‡½æ•°/ç±»ä¸­ã€‚
- ä»£ç éµå¾ªæ•™å­¦æ€§è´¨è¦æ±‚ï¼Œå‡½æ•°å‡æä¾›ä¸­æ–‡ Docstringã€‚
- æ–°å¢åŠŸèƒ½ï¼šä¸»é¢˜åˆ‡æ¢ã€å›½é™…åŒ–ã€æ‰¹é‡æ“ä½œã€æ¨¡å‹ç®¡ç†ã€é«˜çº§åˆ†æç­‰ã€‚
"""

import os
from typing import Optional, Tuple

import streamlit as st
import pandas as pd
import numpy as np

# æ³¨æ„ï¼šä¸ºäº†é™ä½å¯åŠ¨æ—¶çš„ä¾èµ–å‹åŠ›ï¼Œéƒ¨åˆ†ç¬¬ä¸‰æ–¹åº“åœ¨å†…éƒ¨å‡½æ•°ä¸­æ‡’åŠ è½½

# åŸºç¡€æ¨¡å—
from starvis.data_loader import DataLoader
from starvis.preprocessing import Preprocessor
from starvis.features import FeatureEngineer
from starvis.model import ModelTrainer
from starvis.evaluation import Evaluator
from starvis.utils import (
    ensure_data_dir,
    plot_sky_distribution,
    plot_hr_diagram,
    explain_star_class,
    classify_by_rules,
    build_case_dataset,
)
from starvis.testing import (
    test_data_not_empty,
    test_predict_shape,
    test_data_loader_api,
    test_feature_engineer_api,
    test_preprocessor_api,
    test_model_trainer_api,
    test_evaluator_api,
    run_pipeline_quick,
)

# æ–°å¢åŠŸèƒ½æ¨¡å—
from starvis.themes import get_theme_manager, apply_theme
from starvis.i18n import get_i18n_manager, _, set_language
from starvis.batch_operations import create_batch_operations, handle_package_upload, handle_package_download
from starvis.model_management import create_model_manager, handle_model_save, handle_model_load
from starvis.advanced_features import create_advanced_features, render_advanced_filter_ui


def page_header():
    """åœ¨é¡µé¢é¡¶éƒ¨å±•ç¤ºæ ‡é¢˜ä¸èƒŒæ™¯è¯´æ˜ã€‚

    ç‰©ç†æ„ä¹‰ï¼šä¸ºåº”ç”¨æä¾›æ¸…æ™°çš„å…¥å£ä¸èƒŒæ™¯å›¾ï¼Œåœ¨ç§‘æ™®åœºæ™¯ä¸­æå‡ç”¨æˆ·æ²‰æµ¸æ„Ÿã€‚
    """
    # åº”ç”¨ä¸»é¢˜
    theme_manager = get_theme_manager()
    
    # è®¾ç½®é¡µé¢é…ç½®
    st.set_page_config(
        page_title=_("app_title"), 
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # åº”ç”¨ä¸»é¢˜æ ·å¼
    theme_manager.apply_custom_style("header", """
        .header-container {
            background: linear-gradient(135deg, rgba(79, 172, 254, 0.8) 0%, rgba(0, 242, 254, 0.8) 100%);
            padding: 2rem;
            border-radius: 15px;
            margin-bottom: 2rem;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .header-title {
            color: white !important;
            font-size: 2.5rem !important;
            font-weight: 700 !important;
            text-align: center;
            margin-bottom: 0.5rem;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }
        .header-subtitle {
            color: rgba(255, 255, 255, 0.9) !important;
            font-size: 1.2rem !important;
            text-align: center;
            font-weight: 300;
        }
    """)
    
    # æ˜¾ç¤ºæ ‡é¢˜
    st.markdown(f"""
        <div class="header-container">
            <h1 class="header-title">{_("app_title")}</h1>
            <p class="header-subtitle">{_("app_subtitle")}</p>
        </div>
    """, unsafe_allow_html=True)


def sidebar_nav() -> str:
    """æ„å»ºä¾§è¾¹æ å¯¼èˆªä¸è¶…å‚æ•°é…ç½®ã€‚

    è¿”å›å€¼ï¼šå½“å‰é€‰æ‹©çš„é¡µé¢åç§°ã€‚
    ç‰©ç†æ„ä¹‰ï¼šå°†ä¸åŒä»»åŠ¡åˆ†åŒºï¼Œæå‡ç§‘ç ”å·¥ä½œä¸ç§‘æ™®æ•™å­¦çš„æ“ä½œæ•ˆç‡ã€‚
    """
    # åº”ç”¨ä¸»é¢˜åˆ°ä¾§è¾¹æ 
    theme_manager = get_theme_manager()
    
    st.sidebar.title(_("settings"))
    
    # ä¸»é¢˜åˆ‡æ¢
    with st.sidebar.expander(_("nav_theme_settings")):
        available_themes = theme_manager.get_available_themes()
        current_theme = st.selectbox(
            _("select_theme"),
            options=list(available_themes.keys()),
            format_func=lambda x: available_themes[x],
            key="theme_selector"
        )
        if current_theme != theme_manager.current_theme:
            theme_manager.set_theme(current_theme)
            st.success(_("theme_applied", theme_name=available_themes[current_theme]))
            st.rerun()
    
    # è¯­è¨€åˆ‡æ¢
    with st.sidebar.expander(_("nav_language_settings")):
        i18n_manager = get_i18n_manager()
        available_languages = i18n_manager.get_available_languages()
        current_lang = st.selectbox(
            _("select_language"),
            options=list(available_languages.keys()),
            format_func=lambda x: available_languages[x],
            key="language_selector"
        )
        if current_lang != i18n_manager.current_language:
            set_language(current_lang)
            st.success(_("language_applied", language_name=available_languages[current_lang]))
            st.rerun()
    
    st.sidebar.title(_("settings"))
    
    # ä¸»é¢˜åˆ‡æ¢
    with st.sidebar.expander(_("nav_theme_settings")):
        available_themes = theme_manager.get_available_themes()
        current_theme = st.selectbox(
            _("select_theme"),
            options=list(available_themes.keys()),
            format_func=lambda x: available_themes[x],
            key="theme_selector"
        )
        if current_theme != theme_manager.current_theme:
            theme_manager.set_theme(current_theme)
            st.success(_("theme_applied", theme_name=available_themes[current_theme]))
            st.rerun()
    
    # è¯­è¨€åˆ‡æ¢
    with st.sidebar.expander(_("nav_language_settings")):
        i18n_manager = get_i18n_manager()
        available_languages = i18n_manager.get_available_languages()
        current_lang = st.selectbox(
            _("select_language"),
            options=list(available_languages.keys()),
            format_func=lambda x: available_languages[x],
            key="language_selector"
        )
        if current_lang != i18n_manager.current_language:
            set_language(current_lang)
            st.success(_("language_applied", language_name=available_languages[current_lang]))
            st.rerun()
    
    st.sidebar.title(_("åŠŸèƒ½å¯¼èˆª"))
    page = st.sidebar.radio(
        _("é€‰æ‹©é¡µé¢"),
        [
            "nav_data_overview",
            "nav_model_training", 
            "nav_research_filter",
            "nav_hr_interactive",
            "nav_case_studies",
            "nav_testing_center",
            "nav_batch_operations",
            "nav_model_management",
            "nav_data_augmentation",
            "nav_advanced_filter",
            "nav_auto_tuning",
            "nav_feature_analysis",
            "nav_training_monitor",
            "nav_report_generator"
        ],
        format_func=lambda x: _(x),
        index=0,
    )

    st.sidebar.title(_("è¶…å‚æ•°é…ç½®"))
    train_ratio = st.sidebar.slider(_("train_ratio_config"), 0.5, 0.9, 0.8, 0.05)
    st.session_state["train_ratio"] = train_ratio

    return page


def init_states():
    """åˆå§‹åŒ– Streamlit ä¼šè¯çŠ¶æ€ï¼Œé¿å…é¦–æ¬¡è¿è¡Œç¼ºå°‘é”®å¯¼è‡´å¼‚å¸¸ã€‚

    ç‰©ç†æ„ä¹‰ï¼šç¡®ä¿ç³»ç»Ÿç¨³å¥æ€§ï¼Œä½¿äº¤äº’åœ¨å¤šæ¬¡æ“ä½œé—´ä¿æŒä¸€è‡´çŠ¶æ€ã€‚
    """
    keys = [
        "df",
        "features",
        "X",
        "y",
        "X_train",
        "X_test",
        "y_train",
        "y_test",
        "model",
        "label_encoder",
        "feature_names",
        "train_ratio",
    ]
    for k in keys:
        st.session_state.setdefault(k, None)


def page_data_overview(loader: DataLoader, engineer: FeatureEngineer):
    """é¡µé¢ Aï¼šæ•°æ®æ¦‚è§ˆã€‚

    åŠŸèƒ½ï¼šåŠ è½½ CSV æˆ–ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼›å±•ç¤ºæ•°æ®æ‘˜è¦ä¸å¤©çƒåˆ†å¸ƒï¼ˆra vs decï¼‰ã€‚
    ç‰©ç†æ„ä¹‰ï¼šå¸®åŠ©ç”¨æˆ·äº†è§£æ•°æ®è§„æ¨¡ä¸ç©ºé—´åˆ†å¸ƒï¼Œä¸ºåç»­ç‰¹å¾å·¥ç¨‹ä¸æ¨¡å‹è®­ç»ƒæä¾›ç›´è§‰ã€‚
    """
    st.subheader(_("data_overview_title"))
    uploaded = st.file_uploader(_("data_upload_placeholder"), type=["csv"])

    if st.button(_("load_data_button")):
        try:
            ensure_data_dir()
            if uploaded is not None:
                df = loader.load_from_buffer(uploaded)
            else:
                # è‹¥æœ¬åœ°ä¸å­˜åœ¨åˆ™è‡ªåŠ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
                csv_path = os.path.join("data", "sdss_mock.csv")
                df = loader.load_csv_or_mock(csv_path)
            st.session_state["df"] = df

            info = loader.get_info(df)
            st.success(_("data_load_success", rows=info["rows"], cols=info["cols"], memory_mb=info["memory_mb"]))

            st.write(_("data_preview"))
            st.dataframe(df.head(10))

            fig = plot_sky_distribution(df)
            st.plotly_chart(fig, use_container_width=True)

            # é¢„å…ˆè®¡ç®—åŸºç¡€ç‰¹å¾ï¼Œä¾¿äºåç»­é¡µé¢ä½¿ç”¨
            features_df, feature_names = engineer.build_features(df)
            st.session_state["features"] = features_df
            st.session_state["feature_names"] = feature_names
            st.info(_("features_generated"))
        except Exception as e:
            st.error(_("data_load_error", error=e))


def page_model_training(preprocessor: Preprocessor, trainer: ModelTrainer, evaluator: Evaluator):
    """é¡µé¢ Bï¼šæ¨¡å‹è®­ç»ƒæŠ¥å‘Šã€‚

    åŠŸèƒ½ï¼šæ‰§è¡Œè®­ç»ƒ/æµ‹è¯•é›†åˆ’åˆ†ï¼Œè®­ç»ƒè½¯æŠ•ç¥¨é›†æˆæ¨¡å‹ï¼Œå±•ç¤ºæŒ‡æ ‡ä¸æ··æ·†çŸ©é˜µã€‚
    ç‰©ç†æ„ä¹‰ï¼šé€šè¿‡å¯è§£é‡Šæ€§çš„çº¿æ€§ä¸æ¦‚ç‡æ¨¡å‹èåˆï¼Œæå‡åˆ†ç±»æ€§èƒ½å¹¶ä¿ç•™å¯è§£é‡Šæ€§ã€‚
    """
    st.subheader(_("model_training_title"))
    df = st.session_state.get("df")
    features_df = st.session_state.get("features")
    train_ratio = st.session_state.get("train_ratio", 0.8)

    if df is None or features_df is None:
        st.warning(_("load_data_first"))
        return

    if st.button(_("start_training_button")):
        progress = st.progress(10)
        try:
            X, y, label_encoder = preprocessor.prepare_xy(features_df, df)
            # ä¿å­˜å·²æ‹Ÿåˆçš„é¢„å¤„ç†å™¨åˆ°ä¼šè¯ï¼Œä¾¿äºåç»­ç§‘ç ”ç­›é€‰/æ¡ˆä¾‹æ¼”ç¤ºå¤ç”¨
            st.session_state["preprocessor"] = preprocessor
            progress.progress(30)

            X_train, X_test, y_train, y_test = preprocessor.train_test_split(X, y, train_ratio=train_ratio)
            st.session_state.update({
                "X": X, "y": y,
                "X_train": X_train, "X_test": X_test,
                "y_train": y_train, "y_test": y_test,
                "label_encoder": label_encoder
            })
            progress.progress(60)

            model = trainer.train_voting_classifier(X_train, y_train, weights=(0.6, 0.4))
            st.session_state["model"] = model
            progress.progress(80)

            metrics, fig_cm = evaluator.evaluate(model, X_test, y_test)
            progress.progress(100)

            st.success(
                _("training_complete", accuracy=metrics["accuracy"], precision=metrics["precision"], 
                  recall=metrics["recall"], f1=metrics["f1"])
            )
            st.pyplot(fig_cm)

            # ç‰¹å¾é‡è¦æ€§
            st.markdown(f"### {_(\"feature_importance\")}")
            try:
                fig_imp = evaluator.feature_importance(model, X_test)
                if fig_imp is not None:
                    st.pyplot(fig_imp)
                    st.info(_("feature_importance_info"))
            except Exception as e:
                st.warning(f"ç‰¹å¾é‡è¦æ€§è®¡ç®—å¤±è´¥ï¼š{e}")

        except Exception as e:
            st.error(_("training_error", error=e))


def page_research_filter(preprocessor: Preprocessor, trainer: ModelTrainer):
    """é¡µé¢ Cï¼šç§‘ç ”ç­›é€‰å·¥å…·ã€‚

    åŠŸèƒ½ï¼šæ”¯æŒæ‰¹é‡é¢„æµ‹ CSVï¼Œè¾“å‡ºé«˜ç½®ä¿¡åº¦ä¸éœ€å¤æ ¸æ ‡ç­¾ï¼Œå¹¶æ”¯æŒä¸‹è½½ç»“æœã€‚
    ç‰©ç†æ„ä¹‰ï¼šä¸ºç§‘ç ”åœºæ™¯æä¾›å¿«é€Ÿç­›é€‰èƒ½åŠ›ï¼Œé™ä½äººå·¥æ ‡æ³¨æˆæœ¬ã€‚
    """
    st.subheader(_("research_filter_title"))
    model = st.session_state.get("model")
    df = st.session_state.get("df")
    features_df = st.session_state.get("features")
    label_encoder = st.session_state.get("label_encoder")
    # ä¼˜å…ˆä½¿ç”¨ä¼šè¯ä¸­å·²æ‹Ÿåˆçš„é¢„å¤„ç†å™¨
    preprocessor = st.session_state.get("preprocessor") or preprocessor

    if model is None or df is None or features_df is None or label_encoder is None:
        st.warning(_("model_not_trained"))
        return
    if getattr(preprocessor, "_scaler", None) is None:
        st.warning(_("model_not_trained"))
        return

    uploaded = st.file_uploader(_("upload_for_prediction"), type=["csv"])
    if uploaded is not None:
        try:
            new_df = pd.read_csv(uploaded)
            engineer = FeatureEngineer()
            new_features, _ = engineer.build_features(new_df)

            X_new = preprocessor.transform_features(new_features)
            y_pred_proba = trainer.predict_proba(model, X_new)
            y_pred = y_pred_proba.argmax(axis=1)
            labels = label_encoder.inverse_transform(y_pred)

            # ç½®ä¿¡åº¦åˆ†ç±»
            confidences = y_pred_proba.max(axis=1)
            tag = pd.Series([_("high_confidence") if c >= 0.7 else _("needs_review") for c in confidences], name="review_tag")
            result = new_df.copy()
            result["pred_class"] = labels
            result["confidence"] = confidences
            result = pd.concat([result, tag], axis=1)

            st.success(_("prediction_complete"))
            st.dataframe(result.head(20))

            csv_bytes = result.to_csv(index=False).encode("utf-8")
            st.download_button(_("download_predictions"), data=csv_bytes, file_name="predictions.csv", mime="text/csv")
        except Exception as e:
            st.error(_("prediction_error", error=e))


def page_hr_interactive():
    """é¡µé¢ Dï¼šèµ«ç½—å›¾ç§‘æ™®äº’åŠ¨ã€‚

    åŠŸèƒ½ï¼šç»˜åˆ¶èµ«ç½—å›¾ï¼ˆé¢œè‰²æŒ‡æ•°/æ¸©åº¦ vs æ˜Ÿç­‰/å…‰åº¦ï¼‰ï¼›é€šè¿‡æ»‘å—è°ƒæ•´æœ‰æ•ˆæ¸©åº¦ã€é‡‘å±ä¸°åº¦ï¼Œå®æ—¶ç»™å‡ºåˆ†ç±»ä¸ç§‘æ™®è§£é‡Šï¼Œå¹¶åœ¨å›¾ä¸­é«˜äº®å¯¹åº”åŒºåŸŸã€‚
    ç‰©ç†æ„ä¹‰ï¼šé€šè¿‡äº’åŠ¨è®©å­¦ç”Ÿç†è§£ä¸åŒæ’æ˜Ÿç±»å‹åœ¨èµ«ç½—å›¾ä¸Šçš„åˆ†å¸ƒä¸æ¼”åŒ–é˜¶æ®µã€‚
    """
    st.subheader("èµ«ç½—å›¾ç§‘æ™®äº’åŠ¨")
    df = st.session_state.get("df")
    features_df = st.session_state.get("features")
    if df is None or features_df is None:
        st.warning("è¯·å…ˆåœ¨â€˜æ•°æ®æ¦‚è§ˆâ€™é¡µé¢åŠ è½½æ•°æ®ã€‚")
        return

    col1, col2 = st.columns([1, 1])
    with col1:
        temp = st.slider("æœ‰æ•ˆæ¸©åº¦ (K)", 3000, 15000, 6000, 100)
        feh = st.slider("é‡‘å±ä¸°åº¦ [Fe/H]", -2.5, 0.5, -0.2, 0.1)
        classification = classify_by_rules(temp, feh)
        st.info(f"åˆ¤å®šç±»å‹ï¼š{classification}")
        explain, img_url = explain_star_class(classification)
        st.image(img_url, caption=classification, use_container_width=True)
        st.write(explain)

    with col2:
        fig_hr = plot_hr_diagram(df, features_df, highlight_point=True, temp=temp)
        st.plotly_chart(fig_hr, use_container_width=True)


def page_cases(preprocessor: Preprocessor, trainer: ModelTrainer):
    """é¡µé¢ï¼šå…¸å‹æ¡ˆä¾‹æ¼”ç¤ºã€‚

    åŠŸèƒ½ï¼šä¸€é”®åŠ è½½å¤ªé˜³ã€å¤©ç‹¼æ˜Ÿã€å‚å®¿å››ç­‰æ¡ˆä¾‹ï¼Œå±•ç¤ºæ¨¡å‹åˆ†ç±»ä¸æ¦‚ç‡åˆ†å¸ƒã€‚
    ç‰©ç†æ„ä¹‰ï¼šé€šè¿‡ç†Ÿæ‚‰çš„æ’æ˜Ÿä¾‹å­å¸®åŠ©å­¦ç”Ÿå»ºç«‹ç›´è§‰ï¼Œç†è§£æ¨¡å‹è¾“å‡ºã€‚
    """
    st.subheader("å…¸å‹æ¡ˆä¾‹æ¼”ç¤º")

    model = st.session_state.get("model")
    label_encoder = st.session_state.get("label_encoder")
    # ä½¿ç”¨è®­ç»ƒé˜¶æ®µä¿å­˜çš„é¢„å¤„ç†å™¨
    preprocessor = st.session_state.get("preprocessor") or preprocessor
    if model is None or label_encoder is None:
        st.warning("è¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒã€‚")
        return

    if st.button("ä¸€é”®åŠ è½½æ¡ˆä¾‹"):
        try:
            df_cases = build_case_dataset()
            engineer = FeatureEngineer()
            case_features, feature_names = engineer.build_features(df_cases)
            X_case = preprocessor.transform_features(case_features)
            y_pred_proba = trainer.predict_proba(model, X_case)
            y_pred = y_pred_proba.argmax(axis=1)
            labels = label_encoder.inverse_transform(y_pred)

            df_show = df_cases[["name", "g", "r", "redshift", "feh"]].copy()
            df_show["ç±»åˆ«"] = labels
            df_show["ç½®ä¿¡åº¦"] = y_pred_proba.max(axis=1)
            st.dataframe(df_show)

            st.info("ç¤ºä¾‹ç»“æœè¡¨æ˜ï¼šçº¢ç§»ä¸ g-r é¢œè‰²æ˜¯åˆ†ç±»å…³é”®è¦ç´ ä¹‹ä¸€ã€‚")
        except Exception as e:
            st.error(f"æ¡ˆä¾‹æ¼”ç¤ºå¤±è´¥ï¼š{e}")


def page_tests():
    """é¡µé¢ï¼šæµ‹è¯•ä¸­å¿ƒã€‚

    æä¾›æ¨¡å—çº§ä¸ç«¯åˆ°ç«¯æµ‹è¯•å…¥å£ï¼Œå±•ç¤ºé€šè¿‡/å¤±è´¥ä¸å…³é”®æŒ‡æ ‡ã€‚
    """
    st.subheader("æµ‹è¯•ä¸­å¿ƒï¼šä¸€é”®éªŒè¯å„æ¨¡å—ä¸ç«¯åˆ°ç«¯æµç¨‹")
    col_run, col_info = st.columns([1, 2])

    with col_run:
        run_all = st.button("è¿è¡Œæ‰€æœ‰æ¨¡å—æµ‹è¯•")
        run_e2e = st.button("ä¸€é”®ç«¯åˆ°ç«¯éªŒè¯")

    # åˆå§‹åŒ–å·¥å…·å®ä¾‹ï¼ˆå±€éƒ¨ä½¿ç”¨ï¼Œé¿å…å½±å“å…¨å±€çŠ¶æ€ï¼‰
    loader = DataLoader()
    engineer = FeatureEngineer()
    preprocessor = Preprocessor()
    trainer = ModelTrainer()
    evaluator = Evaluator()

    if run_all:
        try:
            st.write("â€”â€” æ•°æ®åŠ è½½æ¨¡å—æµ‹è¯• â€”â€”")
            ok, df, info = test_data_loader_api(loader)
            st.write({"é€šè¿‡": ok, **info})
            if not ok:
                st.error("æ•°æ®åŠ è½½æµ‹è¯•æœªé€šè¿‡ï¼šæ•°æ®ä¸ºç©ºã€‚")
                return

            st.write("â€”â€” ç‰¹å¾å·¥ç¨‹æ¨¡å—æµ‹è¯• â€”â€”")
            features_df, names = test_feature_engineer_api(engineer, df)
            st.write({"ç‰¹å¾æ•°": len(names), "æ ·æœ¬æ•°": len(features_df)})

            st.write("â€”â€” é¢„å¤„ç†æ¨¡å—æµ‹è¯• â€”â€”")
            X, y, le = test_preprocessor_api(preprocessor, features_df, df)
            st.write({"X_shape": list(X.shape), "y_len": int(len(y)), "ç±»åˆ«æ•°": int(len(le.classes_))})

            st.write("â€”â€” æ¨¡å‹è®­ç»ƒæ¨¡å—æµ‹è¯• â€”â€”")
            model, proba_shape = test_model_trainer_api(trainer, X, y)
            st.write({"é¢„æµ‹æ¦‚ç‡å½¢çŠ¶": list(proba_shape)})
            if not test_predict_shape(np.empty(proba_shape)):
                st.error("é¢„æµ‹æ¦‚ç‡å½¢çŠ¶ä¸ç¬¦åˆé¢„æœŸã€‚")
                return

            st.write("â€”â€” è¯„ä¼°æ¨¡å—æµ‹è¯• â€”â€”")
            metrics, fig_cm = test_evaluator_api(evaluator, model, X[:1000], y[:1000])
            st.json(metrics)
            if fig_cm is not None:
                st.pyplot(fig_cm)
            else:
                st.info("æœªç”Ÿæˆæ··æ·†çŸ©é˜µå›¾ã€‚")
            st.success("æ¨¡å—çº§æµ‹è¯•å…¨éƒ¨é€šè¿‡ âœ…")
        except Exception as e:
            st.error(f"æµ‹è¯•è¿è¡Œå¤±è´¥ï¼š{e}")

    if run_e2e:
        try:
            result = run_pipeline_quick(loader, engineer, preprocessor, trainer, evaluator)
            st.write({
                "æ•°æ®è¡Œæ•°": result["rows"],
                "æ ¸å¿ƒç‰¹å¾æ•°": result["n_features"],
                "è®­ç»ƒé›†å¤§å°": result["train_size"],
                "æµ‹è¯•é›†å¤§å°": result["test_size"],
            })
            st.subheader("è¯„ä¼°æŒ‡æ ‡")
            st.json(result["metrics"])
            st.subheader("æ··æ·†çŸ©é˜µ")
            if result["fig_cm"] is not None:
                st.pyplot(result["fig_cm"])  # seaborn å¯é€‰ï¼Œå·²åœ¨ Evaluator ä¸­å¤„ç†
            else:
                st.info("æœªç”Ÿæˆæ··æ·†çŸ©é˜µå›¾ã€‚")
            st.success("ç«¯åˆ°ç«¯æµç¨‹éªŒè¯é€šè¿‡ âœ…")
        except Exception as e:
            st.error(f"ç«¯åˆ°ç«¯æµç¨‹å¤±è´¥ï¼š{e}")


def run_app():
    """ä¸»ç¨‹åºå…¥å£ï¼šç»„è£…é¡µé¢å¹¶å¤„ç†å¯¼èˆªé€»è¾‘ã€‚

    ç‰©ç†æ„ä¹‰ï¼šå°†å„æ¨¡å—åŠŸèƒ½æœ‰æœºç»“åˆï¼Œå½¢æˆç§‘ç ”ä¸ç§‘æ™®åŒæ¨¡å¼å¹³å°ã€‚
    """
    page_header()
    init_states()
    page = sidebar_nav()

    # åˆå§‹åŒ–æ¨¡å—å®ä¾‹
    loader = DataLoader()
    preprocessor = Preprocessor()
    engineer = FeatureEngineer()
    trainer = ModelTrainer()
    evaluator = Evaluator()

    # é¡µé¢è·¯ç”±
    page_map = {
        "nav_data_overview": lambda: page_data_overview(loader, engineer),
        "nav_model_training": lambda: page_model_training(preprocessor, trainer, evaluator),
        "nav_research_filter": lambda: page_research_filter(preprocessor, trainer),
        "nav_hr_interactive": page_hr_interactive,
        "nav_case_studies": lambda: page_cases(preprocessor, trainer),
        "nav_testing_center": page_tests,
        "nav_batch_operations": page_batch_operations,
        "nav_model_management": page_model_management,
        "nav_data_augmentation": page_data_augmentation,
        "nav_advanced_filter": lambda: page_advanced_filter(preprocessor),
        "nav_auto_tuning": page_auto_tuning,
        "nav_feature_analysis": page_feature_analysis,
        "nav_training_monitor": page_training_monitor,
        "nav_report_generator": page_report_generator,
    }

    # æ‰§è¡Œå¯¹åº”é¡µé¢
    if page in page_map:
        page_map[page]()
    else:
        st.error(f"é¡µé¢ '{page}' æœªæ‰¾åˆ°")


# æ–°å¢é¡µé¢å‡½æ•°
def page_batch_operations():
    """æ‰¹é‡æ“ä½œé¡µé¢ã€‚"""
    st.subheader(_("batch_operations_title"))
    
    tab1, tab2, tab3 = st.tabs([_("upload_zip"), _("download_zip"), _("package_contents")])
    
    with tab1:
        package_info = handle_package_upload()
        if package_info:
            st.json(package_info.get("metadata", {}))
    
    with tab2:
        # è·å–å½“å‰ä¼šè¯æ•°æ®
        df = st.session_state.get("df")
        model = st.session_state.get("model")
        
        if df is not None and model is not None:
            package_name = st.text_input(_("package_name"), value="research_package")
            if st.button(_("create_package")):
                # å‡†å¤‡æ•°æ®æ–‡ä»¶
                data_files = {
                    "data.csv": df,
                    "features.csv": st.session_state.get("features", pd.DataFrame())
                }
                
                # å‡†å¤‡æ¨¡å‹æ–‡ä»¶
                import joblib
                model_bytes = joblib.dumps(model)
                model_files = {
                    "model.pkl": model_bytes
                }
                
                # å‡†å¤‡æŠ¥å‘Šæ–‡ä»¶
                report_files = {
                    "README.md": f"# {package_name}\\n\\nGenerated on {pd.Timestamp.now()}",
                    "metadata.json": str(st.session_state)
                }
                
                handle_package_download(
                    package_name=package_name,
                    data_files=data_files,
                    model_files=model_files,
                    report_files=report_files
                )
        else:
            st.warning("è¯·å…ˆåŠ è½½æ•°æ®å¹¶è®­ç»ƒæ¨¡å‹")
    
    with tab3:
        batch_ops = create_batch_operations()
        packages = batch_ops.list_packages()
        
        if packages:
            for pkg in packages:
                col1, col2, col3, col4 = st.columns([2, 2, 1, 1])
                with col1:
                    st.write(pkg["name"])
                with col2:
                    st.write(pkg["created_at"])
                with col3:
                    st.write(f"{pkg['size'] / 1024 / 1024:.1f} MB")
                with col4:
                    if st.button(_("delete"), key=f"del_{pkg['name']}"):
                        batch_ops.delete_package(pkg["name"])
                        st.rerun()


def page_model_management():
    """æ¨¡å‹ç®¡ç†é¡µé¢ã€‚"""
    st.subheader(_("model_management_title"))
    
    manager = create_model_manager()
    models = manager.list_models()
    
    if not models:
        st.info(_("no_models_found"))
        return
    
    # æ˜¾ç¤ºæ¨¡å‹åˆ—è¡¨
    for model in models:
        col1, col2, col3, col4, col5 = st.columns([2, 1, 1, 1, 2])
        
        with col1:
            st.write(f"{model['name']} v{model['version']}")
        with col2:
            status_color = "ğŸŸ¢" if model['status'] == 'active' else "âšª"
            st.write(f"{status_color} {model['status']}")
        with col3:
            accuracy = model['performance_metrics'].get('accuracy', 0)
            st.write(f"{accuracy:.1%}")
        with col4:
            st.write(f"{model['size'] / 1024:.1f} KB")
        with col5:
            if model['status'] != 'active':
                if st.button(_("rollback_model"), key=f"rollback_{model['name']}_{model['version']}"):
                    if manager.rollback_model(model['name'], model['version']):
                        st.success(_("model_rollback"))
                        st.rerun()
            
            if st.button(_("delete_model"), key=f"delete_{model['name']}_{model['version']}"):
                if manager.delete_model(model['name'], model['version']):
                    st.success(_("model_deleted"))
                    st.rerun()


def page_data_augmentation():
    """æ•°æ®å¢å¼ºé¡µé¢ã€‚"""
    st.subheader(_("data_augmentation_title"))
    
    df = st.session_state.get("df")
    if df is None:
        st.warning("è¯·å…ˆåŠ è½½æ•°æ®")
        return
    
    # è·å–ç‰¹å¾å’Œæ ‡ç­¾
    features_df = st.session_state.get("features")
    if features_df is None:
        engineer = FeatureEngineer()
        features_df, _ = engineer.build_features(df)
    
    # å‡†å¤‡æ•°æ®
    X = features_df.values
    y = df['class'].values if 'class' in df.columns else np.zeros(len(df))
    
    # SMOTEé…ç½®
    col1, col2 = st.columns(2)
    with col1:
        sampling_strategy = st.selectbox("é‡‡æ ·ç­–ç•¥", ["auto", "minority", "not minority", "all"])
    with col2:
        k_neighbors = st.number_input("Kè¿‘é‚»æ•°é‡", min_value=1, max_value=20, value=5)
    
    if st.button(_("apply_smote")):
        try:
            adv_features = create_advanced_features()
            X_resampled, y_resampled, stats = adv_features.apply_smote(
                X, y, sampling_strategy=sampling_strategy, k_neighbors=k_neighbors
            )
            
            st.success(_("smote_applied"))
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            col1, col2 = st.columns(2)
            with col1:
                st.write(_("original_distribution"))
                st.json(stats["original_distribution"])
            with col2:
                st.write(_("augmented_distribution"))
                st.json(stats["augmented_distribution"])
            
            st.write(f"æ•°æ®å¢å¼ºæ¯”ä¾‹: {stats['augmentation_ratio']:.2f}x")
            
            # æ›´æ–°ä¼šè¯çŠ¶æ€
            st.session_state["X_resampled"] = X_resampled
            st.session_state["y_resampled"] = y_resampled
            
        except Exception as e:
            st.error(f"SMOTEåº”ç”¨å¤±è´¥: {str(e)}")


def page_advanced_filter(preprocessor: Preprocessor):
    """é«˜çº§ç­›é€‰é¡µé¢ã€‚"""
    st.subheader(_("advanced_filter_title"))
    
    df = st.session_state.get("df")
    if df is None:
        st.warning("è¯·å…ˆåŠ è½½æ•°æ®")
        return
    
    # ä½¿ç”¨é€šç”¨çš„é«˜çº§ç­›é€‰ç•Œé¢
    filtered_df = render_advanced_filter_ui(df)
    
    if filtered_df is not None:
        st.write("ç­›é€‰ç»“æœ:")
        st.dataframe(filtered_df)


def page_auto_tuning():
    """è‡ªåŠ¨è°ƒä¼˜é¡µé¢ã€‚"""
    st.subheader(_("auto_tuning_title"))
    
    # æ£€æŸ¥å¿…è¦çš„æ•°æ®
    X_train = st.session_state.get("X_train")
    y_train = st.session_state.get("y_train")
    
    if X_train is None or y_train is None:
        st.warning("è¯·å…ˆè®­ç»ƒæ¨¡å‹ä»¥è·å–è®­ç»ƒæ•°æ®")
        return
    
    # è°ƒä¼˜é…ç½®
    col1, col2 = st.columns(2)
    with col1:
        method = st.selectbox(_("tuning_method"), ["grid", "random", "bayesian"])
    with col2:
        cv_folds = st.number_input(_("cv_folds"), min_value=2, max_value=10, value=5)
    
    # å‚æ•°ç½‘æ ¼é…ç½®
    st.write("å‚æ•°é…ç½®:")
    param_grid = {}
    
    if st.checkbox("è°ƒä¼˜é€»è¾‘å›å½’"):
        col1, col2 = st.columns(2)
        with col1:
            C_values = st.text_input("Cå‚æ•°èŒƒå›´", value="0.1,1,10")
        with col2:
            max_iter_values = st.text_input("max_iterå‚æ•°èŒƒå›´", value="100,200,500")
        
        param_grid['logisticregression__C'] = [float(x) for x in C_values.split(',')]
        param_grid['logisticregression__max_iter'] = [int(x) for x in max_iter_values.split(',')]
    
    if st.button(_("start_tuning")):
        try:
            # åˆ›å»ºåŸºç¡€æ¨¡å‹
            from sklearn.linear_model import LogisticRegression
            from sklearn.naive_bayes import GaussianNB
            from sklearn.ensemble import VotingClassifier
            
            base_model = VotingClassifier(
                estimators=[
                    ('lr', LogisticRegression(max_iter=500)),
                    ('nb', GaussianNB())
                ],
                voting='soft',
                weights=[0.6, 0.4]
            )
            
            # æ‰§è¡Œè°ƒä¼˜
            adv_features = create_advanced_features()
            tuning_results = adv_features.hyperparameter_tuning(
                base_model, X_train, y_train, param_grid, method=method, cv=cv_folds
            )
            
            st.success(_("tuning_complete"))
            
            # æ˜¾ç¤ºç»“æœ
            col1, col2 = st.columns(2)
            with col1:
                st.write(_("best_params"))
                st.json(tuning_results["best_params"])
            with col2:
                st.write(_("best_score"))
                st.metric("Best Score", f"{tuning_results['best_score']:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            st.session_state["best_model"] = tuning_results["best_model"]
            
        except Exception as e:
            st.error(_("tuning_error", error=str(e)))


def page_feature_analysis():
    """ç‰¹å¾åˆ†æé¡µé¢ã€‚"""
    st.subheader(_("feature_analysis_title"))
    
    # æ£€æŸ¥å¿…è¦çš„æ•°æ®
    model = st.session_state.get("model")
    X_test = st.session_state.get("X_test")
    feature_names = st.session_state.get("feature_names")
    
    if model is None or X_test is None:
        st.warning("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
        return
    
    tab1, tab2 = st.tabs([_("shap_analysis"), _("feature_importance_plot")])
    
    with tab1:
        if st.button(_("generate_shap")):
            try:
                adv_features = create_advanced_features()
                shap_results = adv_features.shap_analysis(
                    model, X_test, feature_names=feature_names
                )
                
                st.success(_("shap_generated"))
                
                # æ˜¾ç¤ºSHAPå›¾
                if shap_results["summary_plot"]:
                    st.write(_("shap_summary"))
                    st.pyplot(shap_results["summary_plot"])
                
                if shap_results["waterfall_plot"]:
                    st.write(_("shap_waterfall"))
                    st.pyplot(shap_results["waterfall_plot"])
                
                # æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§
                st.write("ç‰¹å¾é‡è¦æ€§æ’å:")
                importance_df = pd.DataFrame({
                    'feature': feature_names or range(len(shap_results["feature_importance"])),
                    'importance': shap_results["feature_importance"]
                }).sort_values('importance', ascending=False)
                
                st.dataframe(importance_df)
                
            except Exception as e:
                st.error(_("shap_error", error=str(e)))
    
    with tab2:
        # æ˜¾ç¤ºä¼ ç»Ÿçš„ç‰¹å¾é‡è¦æ€§
        st.write("ä¼ ç»Ÿç‰¹å¾é‡è¦æ€§åˆ†æ:")
        # è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–ç‰¹å¾é‡è¦æ€§åˆ†ææ–¹æ³•


def page_training_monitor():
    """è®­ç»ƒç›‘æ§é¡µé¢ã€‚"""
    st.subheader(_("training_monitor_title"))
    
    # æ£€æŸ¥å¿…è¦çš„æ•°æ®
    X_train = st.session_state.get("X_train")
    y_train = st.session_state.get("y_train")
    X_test = st.session_state.get("X_test")
    y_test = st.session_state.get("y_test")
    
    if X_train is None or y_train is None or X_test is None or y_test is None:
        st.warning("è¯·å…ˆè®­ç»ƒæ¨¡å‹ä»¥è·å–è®­ç»ƒå’Œæµ‹è¯•æ•°æ®")
        return
    
    # ç›‘æ§é…ç½®
    col1, col2 = st.columns(2)
    with col1:
        epochs = st.number_input("è®­ç»ƒè½®æ•°", min_value=10, max_value=1000, value=100)
    with col2:
        monitor_interval = st.slider("ç›‘æ§é—´éš”(ç§’)", min_value=0.1, max_value=5.0, value=1.0)
    
    if st.button(_("start_monitoring")):
        try:
            # è·å–æ¨¡å‹
            model = st.session_state.get("model")
            if model is None:
                # åˆ›å»ºæ–°æ¨¡å‹ç”¨äºæ¼”ç¤º
                from sklearn.linear_model import LogisticRegression
                model = LogisticRegression(max_iter=epochs)
            
            adv_features = create_advanced_features()
            
            # å¯åŠ¨ç›‘æ§
            st.session_state['stop_training'] = False
            monitor_results = adv_features.training_monitor(
                model, X_train, y_train, X_test, y_test, 
                epochs=epochs, monitor_interval=monitor_interval
            )
            
            st.success(_("monitoring_completed"))
            st.json(monitor_results)
            
        except Exception as e:
            st.error(f"ç›‘æ§å¤±è´¥: {str(e)}")


def page_report_generator():
    """æŠ¥å‘Šç”Ÿæˆé¡µé¢ã€‚"""
    st.subheader(_("report_generator_title"))
    
    # æŠ¥å‘Šé…ç½®
    with st.form("report_form"):
        col1, col2 = st.columns(2)
        with col1:
            title = st.text_input(_("report_title"), value="æ’æ˜Ÿåˆ†ç±»ç ”ç©¶æŠ¥å‘Š")
            author = st.text_input(_("report_author"), value="ç ”ç©¶å›¢é˜Ÿ")
        with col2:
            template = st.selectbox(_("report_template"), ["academic_poster", "technical_report", "custom_report"])
        
        abstract = st.text_area(_("report_abstract"), value="æœ¬æŠ¥å‘Šæ€»ç»“äº†æ’æ˜Ÿåˆ†ç±»ç ”ç©¶çš„æœ€æ–°è¿›å±•...")
        
        # å†…å®¹é…ç½®
        content = {}
        if st.checkbox("åŒ…å«æ–¹æ³•è®º"):
            content['methodology'] = st.text_area("æ–¹æ³•è®ºå†…å®¹", value="ä½¿ç”¨äº†æœºå™¨å­¦ä¹ æ–¹æ³•è¿›è¡Œæ’æ˜Ÿåˆ†ç±»...")
        
        if st.checkbox("åŒ…å«ç»“æœ"):
            content['results'] = st.text_area("ç»“æœå†…å®¹", value="æ¨¡å‹è¾¾åˆ°äº†è¾ƒé«˜çš„åˆ†ç±»å‡†ç¡®ç‡...")
        
        if st.checkbox("åŒ…å«ç»“è®º"):
            content['conclusions'] = st.text_area("ç»“è®ºå†…å®¹", value="ç ”ç©¶è¡¨æ˜æœºå™¨å­¦ä¹ æ–¹æ³•åœ¨æ’æ˜Ÿåˆ†ç±»ä¸­å…·æœ‰å¾ˆå¥½çš„åº”ç”¨å‰æ™¯...")
        
        if st.checkbox("åŒ…å«æ€§èƒ½æŒ‡æ ‡"):
            # ä»ä¼šè¯çŠ¶æ€è·å–æ€§èƒ½æŒ‡æ ‡
            if 'model_metrics' in st.session_state:
                content['metrics'] = st.session_state['model_metrics']
            else:
                content['metrics'] = {'accuracy': 0.95, 'precision': 0.94, 'recall': 0.93, 'f1': 0.94}
        
        submitted = st.form_submit_button(_("generate_report"))
        
        if submitted:
            try:
                adv_features = create_advanced_features()
                pdf_content = adv_features.generate_academic_report(
                    title, author, abstract, content, template=template
                )
                
                st.success(_("report_generated"))
                
                # æä¾›ä¸‹è½½
                st.download_button(
                    label=_("download_pdf"),
                    data=pdf_content,
                    file_name=f"{title.replace(' ', '_')}.pdf",
                    mime="application/pdf"
                )
                
            except Exception as e:
                st.error(_("report_error", error=str(e)))


if __name__ == "__main__":
    run_app()